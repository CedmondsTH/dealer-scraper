# ğŸš€ Dealer Scraper - Complete Handoff Guide

**Everything in One Place: For Management, Developers, and Troubleshooting**

---

## ğŸ“§ Executive Summary (For Management)

### What This Application Does

The **Dealer Scraper** is a web-based tool that automatically extracts dealership location data from dealer group websites and exports it to Excel format.

**Think of it as:** Google for dealer locations - instead of manually copying data from websites, this does it automatically in seconds.

### How to Access

**ğŸŒ Live Application:** https://dealer-scraper-production.up.railway.app/

No installation needed - just open in any web browser and use it.

### What It Can Do

âœ… **Extracts 100+ locations in under 30 seconds**  
âœ… **Works with 8+ major dealer groups** (Lithia, Sonic, Group 1, Hudson, etc.)  
âœ… **Handles most dealer websites** automatically via smart generic strategies  
âœ… **Exports to Excel** with all contact information  
âœ… **Hosted online 24/7** - accessible anywhere  

### Supported Dealer Groups (Tested & Working)

```
âœ… Lithia Motors          (200+ locations)
âœ… Sonic Automotive       (138+ locations)
âœ… Group 1 Automotive     (154+ locations)
âœ… Hudson Automotive      (Complex JavaScript sites)
âœ… AutoCanada
âœ… Cooper Auto Family
âœ… Courtesy Automotive
âœ… Ray Skillman
âœ… Most other dealer groups (via generic strategies)
```

### Ongoing Costs

| Item | Cost | Notes |
|------|------|-------|
| **Railway Hosting** | $5-10/month | Keeps app running online 24/7 |
| **GitHub** | Free | Code repository |
| **Domain** | $0 | Uses Railway subdomain |
| **API Keys** | $0 | Optional AI features (not required) |

**Total Monthly Cost:** ~$5-10

### Technical Requirements

If you need to hire a developer to maintain/extend this:

**Required Skills:**
- Python 3.10+ experience
- Web scraping knowledge (BeautifulSoup, Playwright)
- Basic web development (Streamlit)
- Git/GitHub familiarity

**Nice to Have:**
- Docker/Railway deployment experience
- Testing frameworks (pytest)
- CI/CD pipeline knowledge

**Time to Onboard:**
- Experienced Python dev: 1-2 hours
- New to web scraping: 1 day
- Junior dev: 2-3 days

---

## ğŸŒ Where Everything Lives

### Live Application
**URL:** https://dealer-scraper-production.up.railway.app/  
**Status:** Active and deployed  
**Last Updated:** December 2025

### Code Repository
**GitHub:** https://github.com/CedmondsTH/dealer-scraper  
**Branch:** `main` (production)  
**Visibility:** Private (need access)

### Hosting Platform
**Platform:** Railway.app  
**Region:** US East  
**Auto-Deploy:** Yes (on push to main branch)  
**Account:** (credentials needed)

### Automatic Updates
Any code pushed to the `main` branch on GitHub automatically:
1. Runs quality checks (GitHub Actions)
2. Deploys to Railway (3-5 minutes)
3. Goes live at the production URL

---

## ğŸ“‹ Complete Tech Stack

### Required Technologies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DEVELOPMENT ENVIRONMENT                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ğŸ Python 3.10 or 3.11     Programming language            â”‚
â”‚  ğŸ“¦ pip                     Package manager                  â”‚
â”‚  ğŸŒ³ Git 2.x                 Version control                  â”‚
â”‚  ğŸ’» VS Code                 Code editor (recommended)        â”‚
â”‚  ğŸ” GitHub Account          Repository access                â”‚
â”‚  ğŸš‚ Railway Account         Hosting platform                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Python Packages

| Package | Version | Purpose | Required? |
|---------|---------|---------|-----------|
| streamlit | â‰¥1.28.0 | Web interface | âœ… YES |
| pandas | â‰¥1.5.0 | Data manipulation | âœ… YES |
| beautifulsoup4 | â‰¥4.11.0 | HTML parsing | âœ… YES |
| lxml | â‰¥4.9.0 | Fast HTML parser | âœ… YES |
| playwright | â‰¥1.30.0 | Browser automation | âœ… YES |
| requests | â‰¥2.28.0 | HTTP requests | âœ… YES |
| openpyxl | â‰¥3.0.0 | Excel files | âœ… YES |
| python-dotenv | â‰¥1.0.0 | Environment vars | âœ… YES |
| google-generativeai | â‰¥0.3.0 | AI fallback | âš ï¸ Optional |
| openai | â‰¥1.0.0 | AI fallback | âš ï¸ Optional |

### Development Tools (Optional)

- **pytest** - Automated testing
- **black** - Code formatting
- **flake8** - Code quality checks
- **mypy** - Type checking
- **isort** - Import organization

---

## ğŸ—ï¸ System Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                               â”‚
â”‚                     ğŸ‘¤ USER (Web Browser)                     â”‚
â”‚                             â†“                                 â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚   STREAMLIT WEB INTERFACE               â”‚            â”‚
â”‚        â”‚   â€¢ User enters dealer info             â”‚            â”‚
â”‚        â”‚   â€¢ Displays results                    â”‚            â”‚
â”‚        â”‚   â€¢ Downloads Excel                     â”‚            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                       â†“                                       â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚        â”‚   SCRAPER SERVICE (Coordinator)         â”‚            â”‚
â”‚        â”‚   â€¢ Manages workflow                    â”‚            â”‚
â”‚        â”‚   â€¢ Handles retries                     â”‚            â”‚
â”‚        â”‚   â€¢ Coordinates components              â”‚            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                       â†“                                       â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚           â†“                      â†“                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  WEB SCRAPER   â”‚    â”‚  DATA SERVICE  â”‚                   â”‚
â”‚  â”‚  Fetches HTML  â”‚    â”‚  Processes &   â”‚                   â”‚
â”‚  â”‚  from websites â”‚    â”‚  Exports data  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚           â†“                     â†“                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚    14 SCRAPING STRATEGIES            â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚                    â”‚
â”‚  â”‚  â”‚ Lithia â”‚ Sonic  â”‚ Group1 â”‚ +11   â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                    â”‚
â”‚  â”‚  â€¢ 10 Dealer-Specific Strategies     â”‚                    â”‚
â”‚  â”‚  â€¢ 4 Generic Strategies              â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                 â†“                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚        UTILITIES                 â”‚                        â”‚
â”‚  â”‚  â€¢ Address Parser                â”‚                        â”‚
â”‚  â”‚  â€¢ Data Cleaner                  â”‚                        â”‚
â”‚  â”‚  â€¢ Deduplication                 â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                 â†“                                             â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚      â”‚   ğŸ“Š EXCEL OUTPUT    â”‚                               â”‚
â”‚      â”‚   User downloads     â”‚                               â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow (6 Steps)

```
STEP 1: USER INPUT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User enters:        â”‚
â”‚ â€¢ Dealer name       â”‚
â”‚ â€¢ Website URL       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
STEP 2: FETCH WEBPAGE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Download HTML:      â”‚
â”‚ â€¢ Try requests      â”‚
â”‚ â€¢ Use Playwright    â”‚
â”‚   for JS sites      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
STEP 3: SELECT STRATEGY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Choose extractor:   â”‚
â”‚ â€¢ Lithia strategy?  â”‚
â”‚ â€¢ Sonic strategy?   â”‚
â”‚ â€¢ Generic strategy? â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
STEP 4: EXTRACT DATA
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parse HTML for:     â”‚
â”‚ â€¢ Names             â”‚
â”‚ â€¢ Addresses         â”‚
â”‚ â€¢ Phone numbers     â”‚
â”‚ â€¢ Websites          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
STEP 5: CLEAN & VALIDATE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Process data:       â”‚
â”‚ â€¢ Fix addresses     â”‚
â”‚ â€¢ Remove dupes      â”‚
â”‚ â€¢ Validate quality  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
STEP 6: EXPORT TO EXCEL
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Create spreadsheet  â”‚
â”‚ User downloads âœ“    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

### Complete Folder Layout

```
dealer-scraper/
â”‚
â”œâ”€â”€ ğŸ“„ run.py                        â† Main entry point (starts app)
â”œâ”€â”€ âš™ï¸  config.py                     â† All settings & configuration
â”œâ”€â”€ ğŸ“‹ requirements.txt              â† Python packages needed
â”œâ”€â”€ ğŸ“‹ requirements-dev.txt          â† Development tools
â”œâ”€â”€ ğŸ³ Dockerfile                    â† Railway deployment config
â”œâ”€â”€ ğŸš‚ railway.json                  â† Railway settings
â”œâ”€â”€ â–¶ï¸  start.sh                      â† Startup script
â”œâ”€â”€ ğŸ“Š rules.json                    â† Learned scraping patterns
â”œâ”€â”€ ğŸ“„ README.md                     â† Project overview
â”‚
â”œâ”€â”€ ğŸ“ src/                          â† MAIN APPLICATION CODE
â”‚   â”œâ”€â”€ ğŸ“„ models.py                 â† Data structures
â”‚   â”œâ”€â”€ ğŸ“„ exceptions.py             â† Error handling
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ scrapers/                 â† SCRAPING ENGINE
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ base_scraper.py      â† Core logic
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ scraper_registry.py  â† Strategy registration
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ strategy_manager.py  â† Coordinates strategies
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ strategies/           â† 14 EXTRACTION METHODS
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ lithia_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sonic_dealercom_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ group1_automotive_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ hudson_automotive_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ autocanada_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ cooper_auto_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ courtesy_automotive_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ ray_skillman_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ dealercom_content_blocks_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ learned_rule_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ overfuel_locations_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ json_ld_strategy.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ javascript_strategy.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ generic_dealer_strategy.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ğŸ“ extractors/           â† Reusable tools
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ banister_extractor.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ dealeron_extractor.py
â”‚   â”‚       â””â”€â”€ ğŸ“„ heading_address_extractor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ services/                 â† BUSINESS LOGIC
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ scraper_service.py   â† Main coordinator
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ data_service.py      â† Data processing & Excel
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ web_scraper.py       â† Fetches web pages
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ playwright_subprocess.py â† JavaScript sites
â”‚   â”‚   â””â”€â”€ ğŸ“„ rule_store.py        â† Pattern learning
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/                    â† HELPER TOOLS
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ address_parser.py    â† Cleans addresses
â”‚   â”‚   â””â”€â”€ ğŸ“„ data_cleaner.py      â† Removes duplicates
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ ui/                       â† USER INTERFACE
â”‚       â””â”€â”€ ğŸ“„ streamlit_app.py     â† Web app UI
â”‚
â”œâ”€â”€ ğŸ“ tests/                        â† AUTOMATED TESTING
â”‚   â”œâ”€â”€ ğŸ“„ test_basic.py
â”‚   â”œâ”€â”€ ğŸ“„ test_integration_scraping.py
â”‚   â”œâ”€â”€ ğŸ“ unit/                     â† Component tests
â”‚   â””â”€â”€ ğŸ“ integration/              â† Full system tests
â”‚
â”œâ”€â”€ ğŸ“ docs/                         â† DOCUMENTATION
â”‚   â”œâ”€â”€ ğŸ“„ HOW_IT_WORKS.md
â”‚   â”œâ”€â”€ ğŸ“„ HANDOFF_NOTES.md
â”‚   â””â”€â”€ ğŸ“„ PROJECT_STRUCTURE.md
â”‚
â”œâ”€â”€ ğŸ“ .github/workflows/            â† CI/CD AUTOMATION
â”‚   â”œâ”€â”€ ğŸ“„ ci.yml                   â† Runs tests
â”‚   â””â”€â”€ ğŸ“„ integration-tests.yml    â† Daily tests
â”‚
â”œâ”€â”€ ğŸ“ assets/                       â† IMAGES
â”‚   â””â”€â”€ ğŸ“„ trackhawk_logo.png
â”‚
â””â”€â”€ ğŸ“ archive/                      â† OLD CODE (reference only)
```

### Key Files Explained

| File | Purpose | When to Edit |
|------|---------|--------------|
| `run.py` | Starts the application | Rarely - it's the entry point |
| `config.py` | All settings (timeouts, API keys, columns) | Change timeouts, add settings |
| `src/ui/streamlit_app.py` | Web interface code | Change UI text, layout, buttons |
| `src/services/scraper_service.py` | Orchestrates scraping workflow | Modify scraping logic |
| `src/scrapers/strategies/*.py` | Dealer-specific extraction logic | Add new dealer support |
| `src/utils/address_parser.py` | Address cleaning & parsing | Fix address format issues |
| `src/utils/data_cleaner.py` | Deduplication logic | Adjust duplicate detection |
| `requirements.txt` | Python packages | Add new dependencies |
| `Dockerfile` | Deployment configuration | Change deployment settings |
| `start.sh` | Startup script for Railway | Modify startup behavior |

---

## ğŸš€ Setup From Scratch (For Developers)

### Prerequisites Checklist

```
Before starting, you need:

â˜ Computer (Windows, Mac, or Linux)
â˜ Admin/sudo access
â˜ Stable internet
â˜ 2-3 GB free disk space
â˜ 30-60 minutes of time
```

---

### Step 1ï¸âƒ£: Install Python

**Download:** Go to [python.org/downloads](https://www.python.org/downloads/)

**Choose:** Python 3.11 (recommended) or Python 3.10

**âš ï¸ CRITICAL:** During installation, check **"Add Python to PATH"**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python 3.11.x Setup                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  âœ… Add Python 3.11 to PATH        â”‚  â† CHECK THIS!
â”‚  â˜ Install for all users           â”‚
â”‚                                     â”‚
â”‚      [Install Now]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Verify:**
```bash
python --version
# Should show: Python 3.11.x

pip --version
# Should show: pip 23.x.x
```

---

### Step 2ï¸âƒ£: Install Git

**Download:** [git-scm.com](https://git-scm.com/)

**Install:** Use default settings

**Verify:**
```bash
git --version
# Should show: git version 2.x.x
```

**Optional Configuration:**
```bash
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
```

---

### Step 3ï¸âƒ£: Clone Repository

```bash
# Navigate to desired location
cd C:\Projects  # Windows
# OR: cd ~/Projects  # Mac/Linux

# Clone the repository
git clone https://github.com/CedmondsTH/dealer-scraper.git

# Enter directory
cd dealer-scraper

# Verify you're on main branch
git branch
# Should show: * main
```

---

### Step 4ï¸âƒ£: Create Virtual Environment

**Why?** Isolates dependencies from other projects

```bash
# Create virtual environment
python -m venv venv

# Activate it:

# WINDOWS:
venv\Scripts\activate

# MAC/LINUX:
source venv/bin/activate
```

**Success indicator:**
```bash
(venv) C:\Projects\dealer-scraper>
       â†‘
  This shows venv is active
```

---

### Step 5ï¸âƒ£: Install Dependencies

```bash
# Install required packages
pip install -r requirements.txt

# Optional: Install development tools
pip install -r requirements-dev.txt

# Install Playwright browsers
playwright install chromium
```

**Takes:** 2-5 minutes

**What installs:**
```
âœ“ pandas
âœ“ beautifulsoup4
âœ“ lxml
âœ“ requests
âœ“ streamlit
âœ“ playwright
âœ“ openpyxl
... and more
```

---

### Step 6ï¸âƒ£: Configure Environment

**Create `.env` file:**
```bash
# Windows:
type nul > .env

# Mac/Linux:
touch .env
```

**Content (optional):**
```env
# Only needed for AI fallback features
GEMINI_API_KEY=your_key_if_you_have_one
OPENAI_API_KEY=your_key_if_you_have_one
```

**Note:** App works fine without these keys!

---

### Step 7ï¸âƒ£: Run Application

```bash
streamlit run run.py
```

**Expected output:**
```
You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.100:8501
```

**Browser should open automatically!** ğŸ‰

---

### Step 8ï¸âƒ£: Test It Works

**In the web interface:**

1. **Dealer Name:** `Lithia Motors`
2. **Website URL:** `https://www.lithia.com/locations.htm`
3. Click **"Extract Dealerships"**

**âœ… Success:**
```
Successfully extracted 200+ dealerships!
[Download Excel]
```

**âœ… Setup Complete!**

---

## ğŸ”§ Development Workflow

### Standard Development Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DEVELOPMENT CYCLE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£  START â†’ Checkout main branch
    $ git checkout main

2ï¸âƒ£  UPDATE â†’ Pull latest changes
    $ git pull origin main

3ï¸âƒ£  CODE â†’ Make your changes
    (Edit files in VS Code)

4ï¸âƒ£  TEST â†’ Run locally
    $ streamlit run run.py
    Test thoroughly!

5ï¸âƒ£  FORMAT â†’ Clean up code
    $ black src/ tests/
    $ isort src/ tests/

6ï¸âƒ£  STAGE â†’ Add changes
    $ git add .

7ï¸âƒ£  COMMIT â†’ Save changes
    $ git commit -m "Description"

8ï¸âƒ£  PUSH â†’ Send to GitHub
    $ git push origin main

9ï¸âƒ£  DEPLOY â†’ Railway auto-deploys!
    â±ï¸ 3-5 minutes
    ğŸŒ Live at production URL

ğŸ”Ÿ VERIFY â†’ Test live site
    Check everything works!
```

### Deployment Flow Diagram

```
Developer Computer          GitHub              Railway
       â”‚                      â”‚                    â”‚
       â”‚  1. git push         â”‚                    â”‚
       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚                    â”‚
       â”‚                      â”‚                    â”‚
       â”‚                      â”‚  2. Run Tests      â”‚
       â”‚                      â”‚     âœ“ Unit tests   â”‚
       â”‚                      â”‚     âœ“ Linting      â”‚
       â”‚                      â”‚     âœ“ Format       â”‚
       â”‚                      â”‚                    â”‚
       â”‚                      â”‚  3. Tests Pass     â”‚
       â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚
       â”‚                      â”‚                    â”‚
       â”‚                      â”‚          4. Build & Deploy
       â”‚                      â”‚          (3-5 minutes)
       â”‚                      â”‚                    â”‚
       â”‚                      â”‚          5. App Live!
       â”‚                      â”‚          âœ“ Health checks
       â”‚                      â”‚          âœ“ Running
```

---

## ğŸ› Top 5 Issues & How to Fix Them

### Issue #1: ModuleNotFoundError

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ ERROR                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ModuleNotFoundError: No module named 'streamlit' â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cause:**
- Dependencies not installed
- Virtual environment not activated
- Wrong Python version

**Fix:**
```bash
# 1. Activate virtual environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# 2. Reinstall dependencies
pip install -r requirements.txt

# 3. Verify
pip list | grep streamlit
```

---

### Issue #2: Playwright Browser Not Found

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ ERROR                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Error: Chromium browser not found                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cause:**
- Playwright browsers not installed

**Fix:**
```bash
# Install Playwright
pip install playwright

# Install Chromium browser
playwright install chromium

# Linux only: Install dependencies
playwright install-deps chromium
```

---

### Issue #3: App Won't Start

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ ERROR                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Error: File does not exist: run.py               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cause:**
- Wrong directory

**Fix:**
```bash
# Check where you are
pwd  # Mac/Linux
cd   # Windows

# Navigate to project root
cd dealer-scraper

# Verify files exist
ls run.py src/ tests/  # Mac/Linux
dir run.py             # Windows

# Run app
streamlit run run.py
```

---

### Issue #4: Port Already in Use

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ ERROR                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Port 8501 is already in use                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cause:**
- Another Streamlit instance running

**Fix Option A - Use Different Port:**
```bash
streamlit run run.py --server.port 8502
```

**Fix Option B - Kill Process:**
```bash
# Windows:
taskkill /F /IM streamlit.exe

# Mac/Linux:
pkill -f streamlit
```

---

### Issue #5: Railway Deployment Fails

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ RAILWAY ERROR                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Deployment failed                                 â”‚
â”‚ Health check failed                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Common Causes:**

**A. Missing Package**
```bash
# Add to requirements.txt
echo "package-name==1.2.3" >> requirements.txt
git add requirements.txt
git commit -m "Add missing package"
git push origin main
```

**B. Environment Variables**
1. Go to Railway dashboard
2. Click "Variables"
3. Add missing variables
4. Redeploy

**C. Check Logs**
1. Railway dashboard â†’ Deployments
2. Click failed deployment
3. View "Deploy Logs" and "Runtime Logs"
4. Look for error messages

---

## ğŸ¯ Common Development Tasks

### Task 1: Add New Dealer Group Support

**Example: Adding "Penske Automotive"**

**Step 1 - Create strategy file:**
```bash
touch src/scrapers/strategies/penske_strategy.py
```

**Step 2 - Write the strategy:**
```python
# src/scrapers/strategies/penske_strategy.py

from typing import List, Dict, Any
from bs4 import BeautifulSoup
from src.scrapers.base_scraper import ScraperStrategy

class PenskeStrategy(ScraperStrategy):
    """Strategy for Penske Automotive"""
    
    def __init__(self):
        super().__init__()
        self.is_specific = True
    
    def strategy_name(self) -> str:
        return "Penske Automotive HTML"
    
    def can_handle(self, html: str, page_url: str) -> bool:
        return "penskeautomotive.com" in page_url
    
    def extract_dealers(self, html: str, page_url: str) -> List[Dict[str, Any]]:
        soup = BeautifulSoup(html, "lxml")
        dealers = []
        
        # Find dealer containers
        # (Inspect website to find correct selectors)
        for div in soup.find_all('div', class_='dealer-card'):
            name = div.find('h2').get_text(strip=True)
            address = div.find('div', class_='address').get_text(strip=True)
            
            dealers.append({
                'name': name,
                'street': address,
                # ... more fields
            })
        
        return dealers
```

**Step 3 - Register strategy:**
```python
# src/scrapers/strategy_manager.py

from src.scrapers.strategies.penske_strategy import PenskeStrategy

def initialize_strategies() -> None:
    # ... existing strategies ...
    scraper_registry.register(PenskeStrategy())  # Add this
```

**Step 4 - Test:**
```bash
streamlit run run.py
# Test with Penske website
```

---

### Task 2: Change Timeout Settings

```python
# Edit: config.py

class WebScraperConfig:
    timeout: int = 60  # Changed from 30 to 60 seconds
```

---

### Task 3: Modify UI Text

```python
# Edit: src/ui/streamlit_app.py

st.title("Your Custom Title")  # Change this

if st.button("Your Button Text"):  # Change this
    ...
```

---

### Task 4: Add Output Column

```python
# Edit: config.py

class Constants:
    OUTPUT_COLUMNS: List[str] = [
        "Dealership",
        "Your New Column",  # Add here
        "Address",
        ...
    ]
```

Then update scrapers to return this field.

---

## ğŸ” Debugging & Troubleshooting

### Debug Locally

```bash
# Run with verbose logging
streamlit run run.py --logger.level=debug
```

### Check Railway Logs

```
Step 1: Go to https://railway.app

Step 2: Click your project

Step 3: Click "Deployments"

Step 4: Click the deployment you want to check

Step 5: View logs:
  â”œâ”€ Build Logs â†’ Installation process
  â”œâ”€ Deploy Logs â†’ Startup process
  â””â”€ Runtime Logs â†’ Running errors
```

### Test Components Individually

```python
# Create: test_component.py

from src.services.scraper_service import ScraperService

service = ScraperService()
result = service.scrape_dealer_locations(
    'Test Dealer',
    'https://example.com/locations'
)

print(f"Status: {result.status}")
print(f"Dealers: {len(result.dealers)}")
```

Run:
```bash
python test_component.py
```

### Useful Debug Commands

```bash
# Check Python version
python --version

# List installed packages
pip list

# Git status
git status

# Recent commits
git log --oneline -10

# Check which Python
which python  # Mac/Linux
where python  # Windows

# Kill Streamlit processes
pkill -f streamlit  # Mac/Linux
taskkill /F /IM streamlit.exe  # Windows
```

---

## ğŸ“ Maintenance & Support

### If the App Goes Down

**Step 1: Check Railway**
- Go to Railway dashboard
- Check deployment status
- Look for error messages in logs

**Step 2: Try Redeploying**
- Click "Deploy" button in Railway
- Wait 3-5 minutes
- Check if app comes back online

**Step 3: Check GitHub Actions**
- Go to repository â†’ Actions tab
- See if tests are failing
- Review error messages

### If a Specific Dealer Stops Working

**This is normal** - websites change their structure

**What to do:**
1. The app will still work for other dealers
2. A developer needs to update/create a strategy for that dealer
3. Takes 1-3 hours for an experienced developer

### For Code Changes

```bash
# Pull latest code
git pull origin main

# Make changes
# ... edit files ...

# Test locally
streamlit run run.py

# Push changes
git add .
git commit -m "Description"
git push origin main

# Railway auto-deploys in 3-5 minutes
```

---

## ğŸ“Š Project Metrics & Status

### Current Status

| Metric | Value |
|--------|-------|
| **Lines of Code** | ~3,500 |
| **Test Coverage** | Unit + Integration tests |
| **Supported Dealers** | 8+ specific, most generic |
| **Average Extraction Time** | 15-45 seconds |
| **Deployment Time** | 3-5 minutes (automatic) |
| **Uptime** | 99%+ |
| **Documentation** | Comprehensive |

### What's Included

```
âœ… Web-based user interface
âœ… 14 scraping strategies
âœ… Address parsing & cleaning
âœ… Duplicate removal
âœ… Excel export
âœ… Error handling & logging
âœ… Automated testing
âœ… CI/CD pipeline
âœ… Comprehensive documentation
âœ… Production deployment
```

---

## ğŸ“ For the Next Developer

### Onboarding Timeline

| Experience Level | Time to Productive |
|------------------|-------------------|
| **Experienced Python Developer** | 1-2 hours |
| **New to Web Scraping** | 1 day |
| **Junior Developer** | 2-3 days |

### Required Skills

**Must Have:**
- Python 3.10+ experience
- HTML/CSS basics
- Git/GitHub knowledge
- Command line comfort

**Should Have:**
- Web scraping experience (BeautifulSoup)
- HTTP/REST concepts
- Basic testing knowledge

**Nice to Have:**
- Playwright/Selenium
- Streamlit framework
- Docker/Railway
- CI/CD pipelines

### Learning Path

```
Day 1: Setup & Exploration
â”œâ”€ Follow setup guide (30-60 min)
â”œâ”€ Run app locally (10 min)
â”œâ”€ Test with different dealers (30 min)
â””â”€ Read HOW_IT_WORKS.md (1 hour)

Day 2: Code Understanding
â”œâ”€ Explore project structure (1 hour)
â”œâ”€ Read key files (2 hours)
â”œâ”€ Understand data flow (1 hour)
â””â”€ Review scraping strategies (2 hours)

Day 3: Make First Change
â”œâ”€ Pick a small task (30 min)
â”œâ”€ Make the change (1 hour)
â”œâ”€ Test thoroughly (30 min)
â”œâ”€ Deploy to Railway (30 min)
â””â”€ Verify it works (30 min)

Week 2+: Full Productivity
â”œâ”€ Add new dealer support
â”œâ”€ Fix bugs
â”œâ”€ Optimize performance
â””â”€ Add features
```

---

## ğŸ“š Documentation Reference

### All Available Documentation

```
Root Documentation:
â”œâ”€â”€ COMPLETE_HANDOFF_GUIDE.md    â† THIS FILE (everything!)
â”œâ”€â”€ README.md                     â† Project overview
â”œâ”€â”€ HANDOFF_EMAIL_TEMPLATE.md    â† Email template
â”œâ”€â”€ PROJECT_STRUCTURE_VISUAL.md  â† Visual guide
â””â”€â”€ SIMPLIFIED_DIAGRAM.md        â† Flow charts

docs/ Folder:
â”œâ”€â”€ HOW_IT_WORKS.md              â† Architecture deep dive
â”œâ”€â”€ HANDOFF_NOTES.md             â† Maintenance guide
â””â”€â”€ PROJECT_STRUCTURE.md         â† Detailed structure

GitHub:
â””â”€â”€ .github/workflows/README.md  â† CI/CD documentation
```

### External Resources

| Resource | URL | Purpose |
|----------|-----|---------|
| Python Docs | python.org/docs | Language reference |
| Streamlit Docs | docs.streamlit.io | Web framework |
| BeautifulSoup | crummy.com/software/BeautifulSoup | HTML parsing |
| Playwright | playwright.dev/python | Browser automation |
| Railway Docs | docs.railway.app | Hosting |
| Git Docs | git-scm.com/doc | Version control |

---

## âœ… Setup Checklist

Print and check off as you complete:

```
SETUP CHECKLIST:

â˜ Install Python 3.10 or 3.11
â˜ Install Git
â˜ Clone repository
â˜ Create virtual environment
â˜ Activate virtual environment
â˜ Install dependencies (requirements.txt)
â˜ Install Playwright browsers
â˜ Create .env file
â˜ Run app locally
â˜ Test with Lithia Motors
â˜ Download Excel file successfully

OPTIONAL:
â˜ Install dev tools (requirements-dev.txt)
â˜ Set up VS Code
â˜ Configure Git
â˜ Get Railway access
â˜ Get GitHub access

SUCCESS CRITERIA:
â˜ App runs without errors
â˜ Can extract dealerships
â˜ Can download Excel
â˜ Understand project structure
```

---

## ğŸ¯ Quick Command Reference

### Git Commands

```bash
# Clone
git clone https://github.com/CedmondsTH/dealer-scraper.git

# Status
git status

# Pull changes
git pull origin main

# Stage all changes
git add .

# Commit
git commit -m "Description"

# Push
git push origin main

# View history
git log --oneline -10
```

### Python Commands

```bash
# Create virtual env
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Mac/Linux)
source venv/bin/activate

# Install packages
pip install -r requirements.txt

# Run app
streamlit run run.py
```

### Debugging Commands

```bash
# Check versions
python --version
git --version
pip --version

# List packages
pip list

# Kill Streamlit
pkill -f streamlit  # Mac/Linux
taskkill /F /IM streamlit.exe  # Windows
```

---

## ğŸ’¼ Handoff Checklist for Management

Use this to ensure smooth transition:

```
TECHNICAL HANDOFF:

â˜ Railway account access provided
â˜ GitHub repository access granted
â˜ Environment variables documented
â˜ API keys transferred (if any)
â˜ Domain/DNS settings documented
â˜ Backup strategy explained

DOCUMENTATION:

â˜ This guide shared with team
â˜ Email template used for handoff
â˜ All docs available on GitHub
â˜ Video walkthrough recorded (optional)

KNOWLEDGE TRANSFER:

â˜ Live demo conducted
â˜ Q&A session completed
â˜ Key contacts identified
â˜ Escalation path defined

BUSINESS CONTINUITY:

â˜ Monthly costs documented
â˜ Vendor accounts listed
â˜ Deployment process tested
â˜ Rollback procedure documented
â˜ Support contacts provided
```

---

## ğŸš€ Ready to Go!

**This guide contains everything needed to:**

âœ… Understand what the app does  
âœ… Know where everything is hosted  
âœ… Set up the development environment  
âœ… Make code changes  
âœ… Deploy to production  
âœ… Debug issues  
âœ… Add new features  
âœ… Maintain the application  

**For questions or issues:**
1. Check this guide first
2. Review error logs
3. Check GitHub Issues
4. Consult external documentation

---

**Project:** Dealer Scraper  
**Repository:** https://github.com/CedmondsTH/dealer-scraper  
**Live Application:** https://dealer-scraper-production.up.railway.app/  
**Last Updated:** December 2025  
**Status:** âœ… Production-Ready

---

*End of Complete Handoff Guide*

